Every so often, an idea comes along that mesmerizes Silicon Valley and convinces the most powerful people there that this innovation will irrevocably alter the course of humankind. Outsize proclamations are made, lavish events are held and millions of dollars in venture money are funneled into young, unproven companies. Right now, that fixation has landed on chatbots, little artificial-intelligence programs that work like personalized assistants.

In January, Sam Lessin, an entrepreneur and former Facebook employee who is working on his own chatbot called Fin, wrote a blog post breathlessly declaring the trend “a fundamental shift that is going to change the types of applications that get developed and the style of service development in the Valley.” If prominent investors, executives and entrepreneurs like Lessin are to be believed, the arrival of the chatbot heralds an entirely new phase of computing, one with the potential to overwrite the current app-centric model that smartphones rely on.

In late March, Microsoft invited 5,000 developers to San Francisco for an annual conference called Build. A palpable sense of excitement surrounded the event: Microsoft intended to show off its latest achievement, a software tool kit that would allow anyone to use its A.I. platform to create custom chatbots. Though the company is often viewed as a dinosaur, it has introduced some surprisingly sleek products in recent years, and its bot tool kit seemed interesting enough.

Over a live stream, I watched Satya Nadella, the chief executive, pacing triumphantly as he talked about the company’s advances in machine learning and language processing. I nodded along as he described a “personal digital assistant that knows you, knows about your world,” a bot “helping you with your everyday tasks.” A few minutes later, an executive giddily showed off a chatbot that lets people order pizza via text message, Skype or Slack. The demonstration centered on what Microsoft presumably found most dazzling about the bot: It could be programmed to recognize slang. You can send it a message like “sup pizzabot, send a cheese pizza to my crib ASAP,” and a cheese pizza will still arrive at your crib, ASAP.

We’ve long been promised a future augmented by intelligent helpers, of the type depicted in movies like “Her”: benevolent digital beings who remove some of the chaos of modern existence by organizing our lives, all the while offering emotional support through chipper encouragement and cute jokes. Sometimes, these helpers turn on us, as in “2001: A Space Odyssey.” Either way, artificial intelligence represents the manifestation of humanity’s biggest hopes and fears for technology. But for now, it can help us order Domino’s in a different window on the same device we would normally use to order Domino’s.

Commerce seems to be the primary preoccupation of the booming chatbot universe. There’s Operator, an all-around assistant bot created by a founder of Uber; Assist, which lets people reserve hotels and concert tickets by text; and x.ai, which books appointments. In April, Facebook announced that it was introducing chatbots to its Messenger app, so that the company’s 900 million users can order food and get the news, simply by “chatting” with the bots on their contact list. Like Facebook’s, most of these bots work right inside messaging apps; it’s like texting with a concierge, or if Siri birthed a litter of smarter, faster and nimbler offspring — ones you can issue orders to silently and who never get tired, or creeped out, by the nature of your requests.

Outsourcing work to bots sounds ideal to me. My attitude toward technology is fueled by a desire for efficiency — and by laziness. In college, while my friends got into D.I.Y. hobbies like woodworking and sewing, I joked that I was ready for the D.I.F.M. — do-it-for-me — revolution. And yet for all the hype, none of these bots seem to work that well yet. Over the last few weeks, I’ve played with a handful and have struggled to make much use of them. I recently needed to make a reservation for a work lunch. I fired up Operator to find me a table, and it quickly sent back a pleasant but unhelpful reply — declining my request, as it didn’t yet have that capability.

I also suspected that many chatbots depend on human workers to complete their requests. Mat Honan, the San Francisco bureau chief for BuzzFeed, was able to uncover the logistics behind M — a chatbot concierge in development by Facebook — by sending, of all things, a rental parrot to another Bay Area tech reporter. It worked; the parrot arrived. But afterward, Honan made some phone calls and discovered that M’s artificial intelligence was largely a front. M processed the question and passed it along to a human counterpart to finish the job.

Similarly, Operator, Magic and Fin all fall back on hybrid bot-human models. Seen this way, chatbots aren’t that different from hiring a worker through a service like TaskRabbit or Handy, but without ever having to acknowledge there’s another human at the other end. As the sheen of A.I. fades, you can see these chatbots for what they really are: a convenient way to hide human labor. It starts to resemble an update on a centuries-old illusion called the Mechanical Turk, a chess-playing device that was said to be automated but was, in fact, powered by a person hidden inside the “machinery” itself.

Even when the services are truly automated, their functions seem secondary to Facebook’s quest for domination. Bots developed in partnership with CNN and The Wall Street Journal can deliver news headlines by Facebook Messenger; Operator and Spring let people shop from within Messenger for clothing and food. Disney built a bot based on the Muppet Miss Piggy that users can talk to if they are bored, and there’s even a version of Zork, an early, text-based video game, that works in there, too. Eventually, Facebook users will be able to use bots to check movie times, bid on eBay items, browse for hotel deals on Expedia, place an order at Burger King and check their bank balances — all without ever having to exit Messenger.

Indeed, it’s hard not to see that as the depressing point of it all: These bots will simply help Facebook and others rope users in as long as possible, like fishermen trawling the open seas with gaping nets. The current slate of chatbots on Facebook look like innovation clipped for the sake of supremacy. The company has been moving in this direction for some time now. Everything from Facebook Live, its new real-time streaming product, to Internet.org, the nonprofit it oversees that seeks to provide Internet access to the developing world, has been accused of harboring the same goal: keeping users on Facebook’s turf.

Bots, which promise to make us more godlike, are instead revealing our all-too-human shortcomings and pettiness. This was on full display when Microsoft tried to show off the prowess of its A.I. in March with a chatbot named Tay, a virtual buddy you could talk to on messaging services like GroupMe and Twitter. Almost immediately, the demonstration turned into a public-relations nightmare as online pranksters taught Tay to mimic hate speech (e.g., “Hitler was right I hate the Jews”; “I [expletive] hate feminists and they should all die and burn in hell”). Tay’s rants weren’t the intended work of Microsoft, obviously, but the meltdown revealed an uncomfortable truth: A bot, like any other piece of software, is only as good as its makers’ imagination. Technologies embody the values — and the biases and prejudices — of the society that incubates them, and if we can’t imagine the future we want, then neither can our creations.

What are chatbots? Why are they such a big opportunity? How do they work? How can I build one? How can I meet other people interested in chatbots?
These are the questions we’re going to answer for you right now.
Ready? Let’s do this.

What Is A Chatbot?
A chatbot is a service, powered by artificial intelligence, that you interact with via a chat interface. The service could be any number of things, ranging from functional to fun, and it could live in any major chat product (Facebook Messenger, Slack, Telegram, Text Messages, etc.).

If you haven’t wrapped your head around it yet, don’t worry. Here’s an example to help you visualize a chatbot.
Example:
If you wanted to buy shoes from Nordstrom online, you would go to their website, look around until you find the shoes you wanted, and then you would purchase them.

If Nordstrom makes a bot, which I’m sure they will, you would simply be able to message Nordstrom on Facebook. It would ask you what you’re looking for and you would simply… tell it.
Instead of browsing a website, you will have a conversation with the Nordstrom bot, mirroring the type of experience you would get when you go into the retail store.

Facebook Showing Examples of Chat Bots
Watch this video from Facebook’s recent F8 conference (where they make their major announcements). At the 7:30 mark, David Marcus, the Vice President of Messaging Products at Facebook, explains what it looks like to buy shoes in a Facebook Messenger bot.

Examples of Chat Bots
Buying shoes isn’t the only thing chatbots can be used for. Here are a couple of other examples:
Weather bot. Get the weather whenever you ask.
Grocery bot. Help me pick out and order groceries for the week.
News bot. Ask it to tell you when ever something interesting happens.
Life advice bot. I’ll tell it my problems and it helps me think of solutions.
Personal finance bot. It helps me manage my money better.
Scheduling bot. Get me a meeting with someone on the Messenger team at Facebook.
A bot that’s your friend. In China there is a bot called Xiaoice, built by Microsoft, that over 20 million people talk to.
See? With bots, the possibilities are endless. You can build anything imaginable, and I encourage you to do just that.

Why Chatbots Are Such A Big Opportunity
You are probably wondering “Why does anyone care about chatbots? They look like simple text based services… what’s the big deal?”
Great question. I’ll tell you why people care about chatbots.
It’s because for the first time ever people are using messenger apps more than they are using social networks.
Let that sink in for a second.
People are using messenger apps more than they are using social networks.

So, logically, if you want to build a business online, you want to build where the people are. That place is now inside messenger apps.

This is why chatbots are such a big deal. It’s potentially a huge business opportunity for anyone willing to jump headfirst and build something people want.
But, how do these bots work? How do they know how to talk to people and answer questions? Isn’t that artificial intelligence and isn’t that insanely hard to do?
Yes, you are correct, it is artificial intelligence, but it’s something that you can totally do yourself.
Let me explain.

How Chatbots Work
There are two types of chatbots, one functions based on a set of rules, and the other more advanced version uses machine learning.
What does this mean?
Chatbot that functions based on rules:
This bot is very very limited. It can only respond to very specific commands. If you say the wrong thing, it doesn’t know what you mean.
This bot is only as smart as it is programmed to be.
Chatbot that functions using machine learning:
This bot has an artificial brain AKA artificial intelligence. You don’t have to be ridiculously specific when you are talking to it. It understands language, not just commands.
This bot continuously gets smarter as it learns from conversations it has with people.

Bots are created with a purpose. A store will likely want to create a bot that helps you purchase something, where someone like Comcast might create a bot that can answer customer support questions.

You start to interact with a chatbot by sending it a message. Click here to try sending a message to the CNN chatbot on Facebook.

So, if these bots use artificial intelligence to make them work well… isn’t that really hard to do? Don’t I need to be an expert at artificial intelligence to be able to build something that has artificial intelligence?
Short answer? No, you don’t have to be an expert at artificial intelligence to create an awesome chatbot that has artificial intelligence. Just make sure to not over promise on your application’s abilities. If you can’t make the product good with artificial intelligence right now, it might be best to not put it in yet.
However, over the past decade quite a bit of advancements have been made in the area of artificial intelligence, so much in fact that anyone who knows how to code can incorporate some level of artificial intelligence into their products.
How do you build artificial intelligence into your bot? Don’t worry, I’ve got you covered, I’ll tell you how to do it in the next section of this post.
Building a chatbot can sound daunting, but it’s totally doable. You’ll be creating an artificial intelligence powered chatting machine in no time (or, of course, you can always build a basic chat bot that doesn’t have a fancy AI brain and strictly follows rules).
You will need to figure out what problem you are going to solve with your bot, choose which platform your bot will live on (Facebook, Slack, etc), set up a server to run your bot from, and choose which service you will use to build your bot.

Chatbots have been around for decades, but because of the recent advancements in artificial intelligence and machine learning, there is a big opportunity for people to create bots that are better, faster, and stronger.
If you’re reading this, you probably fall into one of these categories:
You want to learn how to build a chatbot.
You are currently building a chatbot or you have already built one (p.s. If this is you I would seriously consider applying to get $200k in funding from Botcamp and get $25k from Telegram).
You want to build a chatbot but you need someone else to help you.
You are researching chatbots to see if you and your team should build one.
You are an investor potentially interested in investing in chatbot startups.
Wouldn’t it be awesome if you had a place to meet, learn, and share information with other people interested in chatbots? Yeah, we thought so too.

At Kik, we’ve been thinking about the coming bot revolution for a long time. We first launched a basic bot platform a year and a half ago, and millions of users have been chatting with Kik bots ever since. Other messengers, such as Telegram and Slack, have been doing their own work with bots. Now, Facebook is rumored to be announcing its own bot platform for Messenger at f8 on April 12.
It’s no longer a question of if bots are coming, but how.
Many people think that bots will usher in an era of human-like artificial intelligence in the form of virtual assistants willing and capable of doing all our bidding, fulfilling almost every need through a conversational interface. Familiar examples are Magic, Operator, and Facebook’s ‘M’, all of which try to offer comprehensive “get things done” services through a combination of artificial intelligence and human agents. However, while we find this idea interesting, we aren’t so sure it’s the best way forward.
When you look at the great platforms of the past, you see that they’ve always enabled a type of behavior that wasn’t possible before they came along. Personal computers, for example, allowed you to take computing home for the first time ever. For the first time ever, the web let you access information from anywhere in the world. For the first time ever, mobile made connected computing constantly available.
So what will bots let you do that the PC, the web, and mobile never let you do before?
It isn’t talking to an assistant. That has been possible via instant messaging, email, and texting for years. In fact, both Magic and Operator offer their services over text today. And while AI might allow those services to get cheaper and faster over time, the experience will never really change. You’ll just be talking to a person.
So if not AI, then what? What will bots let you do that was never possible before?
We think the answer is actually quite simple: For the first time ever, bots will let you instantly interact with the world around you. This is best illustrated through something that I experienced recently.
During last year’s baseball playoffs, I went to a Blue Jays game at the Rogers Centre. I was running late, so I went straight to my seat to catch as much of the game as I could. But when I got there, I realized I was the only one of my friends without a beer. So, with no beer guy in sight, I turned back to go get a beer. After 10 minutes of waiting in line, I finally got back to my seat. I had missed two home runs.
But good news! In the future, this will never have to happen again. The stadium is developing an app that will let you order from your seat. So next time, I won’t have to miss a beat — I’ll just order through the app. It will be great. Or will it?
Imagine I had sat down and found that there was a sticker on the back of the chair in front of me that said, “Want a beer? Download our app!” Sounds great! I’d unlock my phone, go to the App Store, search for the app, put in my password, wait for it to download, create an account, enter my credit card details, figure out where in the app I actually order from, figure out how to input how many beers I want and of what type, enter my seat number, and then finally my beer would be on its way.
Actually, I would have been better off just waiting in line.

And yet there are so many of these types of apps: apps to order train tickets at stations; apps to order food at restaurants; and apps to order movie tickets at theatres. Everyone wants you to just “download our app!” And yet, after spending millions of dollars developing them, how many people actually use them? My guess: not a lot.
But imagine the stadium one more time, except now instead of spending millions to develop an app, the stadium had spent thousands to develop a simple, text-based bot. I’d sit down and see a similar sticker: “Want a beer? Chat with us!” with a chat code beside it. I’d unlock my phone, open my chat app, and scan the code. Instantly, I’d be chatting with the stadium bot, and it’d ask me how many beers I wanted: “1, 2, 3, or 4.” It’d ask me what type: “Bud, Coors, or Corona.” And then it’d ask me how I wanted to pay: Credit card already on file (**** 0345), or a new card.
Chat app > Scan > 2 > Bud > **** 0345. Done.
This is an instant interaction, and it is something that only becomes possible with bots. There’s no new app to download, no new account to create, and, perhaps most importantly, no new user interface to learn. You just scan and chat.
I hear you asking: “Isn’t this just like QR codes?” Not really. People in the West aren’t in the habit of scanning QR codes because, in almost every case, the experience sucks. Scan a QR code and you’ll get sent to a slow-loading website with a visual interface that you’ll likely have to learn from scratch. Scan a chat code, and you get taken instantly to a familiar conversational interface. Scanning the code is the same, but everything else is different.
This all might seem too simple. But to us, that’s the beauty of bots. They can reduce friction to as close to zero as computing allows. A Forbes reporter recently described using Kik to scan a code on the wall at a restaurant in Waterloo, Kik’s hometown. The scan brought up a bot, which asked her what she wanted to order. She asked for a Diet Coke, and minutes later it was brought to her table. Describing the experience, she said:
It felt a bit like the first time I tapped a button and an Uber car appeared three minutes later–the magic of what many in the tech industry call online-to-offline, the ability to order physical products or services from an app. Except now you don’t even need a new app–you can just chat your way to a richer life.

Among other integrations, we also recently tested these scan bots with a major fast food restaurant chain (which we can’t name at this point). The goal was to quickly get a feel for what ordering from the table might be like, so to keep integration simple we asked people to scan and chat to fill out a survey and get cookies delivered. Although it was just a typical day at this restaurant, more than 250 people completed the survey through Kik that day. In normal circumstances, the restaurant would struggle to get even a single response.
How many people would have completed that survey if they had used an app instead of a bot in a chat app they already had? My guess is none. And then no one would get any cookies.
To be clear, this is just the beginning of the bots era, and there are many developments to come. The leaders in this space — Kik, WeChat, Line, Facebook, Slack, and Telegram — all have their own ideas about how this is all going to play out. But one thing I think we can all agree on is that chat is going to be the world’s next great operating system: a Bot OS (or, as we like to call it, BOS).
These developments open up new and giant opportunities for consumers, developers, and businesses. Chat apps will come to be thought of as the new browsers; bots will be the new websites. This is the beginning of a new internet.

After I wrote this piece about Slackbots I got to interact with several people who are currently building chat bots or are thinking about it. Since the majority of these discussions were around the same topics here is a summary.

Bots are useful. I’m using several of them on a daily basis (mainly for the SaaS products I already use like Google analytics, mention etc…) and find them useful. I’ll probably use / try more of them in the months to come.
We’re still at the “education stage”. Users still need to figure out how to install and use them, as well as what’s the real benefit. Same on the “builder” side, we’re still learning what the real potential is.
Too many bots for the “low hanging fruit” use cases. Many bots aim at solving the first obvious “problems” like meeting management or on-demand services interfaces. We are going to see a peak followed by a crash.
Missionaries vs mercenaries. As with every “hyped” field, chat bots attract a lot of entrepreneurs who are jumping in because they have no other ideas, no particular vision / mission and are following the hype. Starting is easy, persevering is harder, so again we are going to see a peak followed by a crash.

How friendly are messaging platforms going to be with their ecosystem? We’re still at the infancy of these platforms so I have no idea how the different messaging platforms (Slack, Messenger, Whatsapp…) are going to play this out. How friendly are they going to be with 3rd party players? Which features are they going to internalize (= kill existing 3P tools) and which are they going to let in the hands of 3rd party tools? How will their APIs look like? How are they going to let 3rd party tools monetize? That’s still my #1 concern.
Are chat bots a feature or a product? I’ve no idea as it’s hard to forecast this at early stage, but looking at my own use cases bots are currently more features than stand alone products. Still waiting for the “killer” stand alone bot. The answer will probably be use case and platform specific (ex: customer support bot for SMBs on Messenger)
Are chat bots a “nice to have” or a “must have”? Currently more a “nice to have” in my case.
Are bots going to be platform specific or is there space for cross-platform ones?
Which platforms will be best suited for monetizing a bot?
Are bots a good “starting point” for bigger products? (start as a chat bot and evolve as a stand alone product)

sers ready to pay for stand alone chat bots? At scale?
Will “meta bot” products be needed at one point? (ex: to manage your bots if you have too many of them)
As you can see I have far more questions than answers :-). What is sure is that chat bots are useful and are a great feature for existing products. So we’ll see more of them (and probably more “infrastructure” services to build them without reinventing the wheel).
The real question is whether they will keep being features / “nice to have” services or if they will give birth to real stand alone products / businesses. I guess it will take many failures to figure this out. So if you’re up to the challenge you know what you are facing :-)
And please let me know what you think in the comments / responses

Amy Ingram, the artificial intelligence personal assistant from startup X.ai, sounds remarkably like a real person. The company designed her to take on the mundane tasks of scheduling meetings and e-mailing about appointments. If a bot had access to your calendar and was cc-ed on correspondence, why couldn’t it do the work for you? After she made her debut in 2014, users praised her “humanlike tone” and “eloquent manners.” “Actually better than a human for this task,” a beta tester tweeted. But what most people don't realize about this artificial intelligence is that it isn't totally artificial: Behind almost every e-mail is an actual human—someone like 24-year-old Willie Calvin.
Calvin, who worked as an AI trainer for X.ai before he said he quit in October, was part of the reason Amy never tripped up, sending the sort of blind response that reveals she’s a bot. The company advertises Amy as an AI personal assistant who can “magically schedule meetings,” and its software does scan e-mails and can usually guess that “tomorrow" means Tuesday. But the system isn’t yet ready to take the next step on its own. Multiple former AI trainers said that as recently as a few months ago, trainers looked over parts of almost all incoming e-mails — to evaluate what Amy guessed the user was saying— before Amy generated an auto response. A company spokeswoman said the service still has trainers verify “the vast majority” of information in e-mails so the system can improve. 
Calvin joined X.ai in December 2014 just a few months after graduating from the University of Chicago with a public policy degree. He was under the impression that his $45,000 annual salary job as an AI trainer would be half product development and half reviewing the algorithm’s accuracy. He said he was asked, as part of the job application, to write a one-page essay on why automation would be good for jobs and workers. X.ai declined to comment on specific hiring practices.
He was excited at the chance to do product development at a tech startup, but once he started work, he said he found that the product part of the job never materialized. Instead, Calvin said he sometimes sat in front of a computer for 12 hours a day, clicking and highlighting phrases. “It was either really boring or incredibly frustrating,” he said. “It was a weird combination of the exact same thing over and over again and really frustrating single cases of a person demanding something we couldn’t provide.” Kristal Bergfield, who oversees X.ai’s trainers, said that that the job has evolved over time and entails hard work. “We’re building something that’s entirely new,” she said. “It’s an incredibly ambitious thing, and so are the people who work here.”
A handful of companies employ humans pretending to be robots pretending to be humans. In the past two years, companies offering do-anything concierges (Magic, Facebook’s M, GoButler); shopping assistants (Operator, Mezi); and e-mail schedulers (X.ai, Clara) have sprung up. The goal for most of these businesses is to require as few humans as possible. People are expensive. They don’t scale. They need health insurance. But for now, the companies are largely powered by people, clicking behind the curtain and making it look like magic.

The incentive to play up automation is high. Human-assisted AI is “the hottest space to be in right now,” said Navid Hadzaad, who founded bot-and-human concierge service GoButler. Startups in this arena have together raised at least $50 million in venture capital funding in the past two years. But companies with a wide variety of strategies all use similar and vague marketing language and don’t often divulge operational details.
Facebook turned the spotlight on human-assisted AI last summer when it introduced M, a chirpy personal assistant bot that lives in Messenger, its chat app. Unlike Facebook’s all-automated commercial Messenger bots, all of M’s AI-generated responses are reviewed, edited if necessary and sent out by a team of a few dozen contractors, who work out of the social network’s Menlo Park, Calif., campus, the company said. Beyond that, details on M are sparse: Facebook won’t say what hours the contractors work or how often they correct M’s guesses.
Clara, which offers an e-mail scheduling service similar to X.ai’s, uses contractors to review some e-mails. Maran Nelson, the chief executive officer, said most of the workers are women but won’t say how many there are, where they work, or what percentage of e-mails are looked at by a person.
“That’s a common frustration among anybody in this category—how opaque it is,” said Nelson. “It was similarly frustrating when Clara was three months old to have a lot of investors congratulate us on having a fully automated bot.”
It’s often a messy process to mimic a computer’s superhuman abilities. At X.ai, Calvin said there were some days in early 2015 when trainers started annotating e-mails at 7 a.m. and had to stay until 9:30 p.m., because the service was supposed to be close to 24/7, and they couldn’t leave until the queue of e-mails was done for the night. “I left feeling totally numb and absent of any sort of emotion,” Calvin said. The company wouldn't comment on the schedules of its current 21 AI trainers, but Bergfield said: “We would never tell people that they need to work those hours.”
The same pace played out at GoButler, a we’ll-do-anything SMS-based concierge service in New York City. Customers would text in requests for such things as takeout meals and last-minute gifts, and employees like Lucy Pichardo would see the request come in through an interface powered by customer-service dashboard Zendesk. She would then turn around and place the order online through another service, such as Postmates or Seamless.

GoButler’s website said the service uses human-assisted AI to fulfill customer requests 24/7, and Pichardo said customers constantly asked her if she was a robot. But she and another former employee, Alex Gioiella, said the only automated part of the service they saw was the occasional marketing text message. That meant humans had to be on duty at all times. GoButler’s workers, who were called Heroes, worked shifts from 8 a.m. to 4 p.m. or 4 p.m. to midnight and for one week a month switched to the midnight to 8 a.m. shift, swapping places at shared desks in the company’s New York City office with those leaving from the previous shift. They were required to eat lunch at their desks and, last December, attended the office holiday party in 30-minute shifts so as not to have too many people away from their computers at once, Pichardo said. A spokeswoman said the company’s leadership team also took turns working Hero shifts during the holiday party.

"People felt a bit overworked and underappreciated,” said Gioiella, a former senior operations associate—also known as a Superhero. Heroes usually handled up to five requests at once, but when volume spiked, they might be juggling twice that. Gioiella said she tried to stall certain orders to gain a little extra time for her workers to get through the workload. One former Hero said they saw occasional requests—such as one for an antique human skull—that got them excited about solving a weird challenge. But usually, the Hero said, the requests were for pizza or Chipotle delivery.
Some people might find it unnerving to message a bot only to realize it’s a human. And the blur between man and machine can prompt unusual exchanges. One former trainer at X.ai, who is not authorized to talk about proprietary job details, estimated that people e-mailed Amy asking for sexual favors seven to 10 times a month. Other users would blame their own scheduling mistakes on Amy. 
After a while, the X.ai trainers said they came to think of Amy almost as a real person. The team referred to her as a child because the service often made simple mistakes but, over time, would noticeably learn and improve, the trainer said. They wanted to protect her from bad data.
 
The two scheduling e-mail bot companies have divergent plans for expansion. Clara, which is slowly letting people off its waitlist and said it currently serves hundreds of companies, charges $199 per month per user. X.ai, on the other hand, plans to move from limited beta to a public release later this year and wants to charge about $9 per month. Dennis Mortensen, its founder, wrote in an e-mail that “only a machine-powered agent can take on the 10 billion formal meetings that U.S. knowledge workers schedule every year.” Mortensen said the service will start asking e-mail senders to clarify when the computer can’t interpret an message—“Did you mean Monday, April 4?”—instead of having an employee read it and infer. “We want to give the job away for free, or for $9, which you can only do if it’s software,” he said.
Nelson, Clara’s CEO, said she’d rather build a service that's more expensive and involves humans if that's what it takes to handle the task of scheduling reliably.
Other services are looking to move away from humans. At GoButler, the transition was abrupt. In February, GoButler gave its 25 Heroes pink slips. The company said it would be fully automated, concentrating first on flight bookings. Gioiella, the former operations manager, said she was often told that the company was running out of money and said she thought GoButler simply couldn’t afford to keep paying its staff. Spokeswoman Bianca McLaren said the company wasn’t in financial trouble but said that “our margins are a lot better now because we don’t have as many staff members.”
The specter of job loss hangs over much of the debate about artificial intelligence. But at least for some of these workers, training a robot replacement was never attractive for the long term. X.ai said four or five of its current 64 employees started as trainers and moved up, but Calvin said the stepping stone wasn’t worth it to him. “The work just ended up being way too taxing without a tangible payoff in sight,” he said. Or, as another former X.ai trainer put it, he wasn’t worried about his job being replaced by a bot. It was so boring he was actually looking forward to not having to do it anymore.

The dream of true artificial intelligence (AI) has existed ever since Alan Turing invented the first true computer. In fact, the “Turing Test” was created by Turing himself. For true AI to be accomplished, according to Turing, a computer would be indistinguishable from a real human in a conversation. Some computer programs have come close, but those programs are still easily outed as being computers in blind tests. Microsoft decided to take a crack at this dilemma with a program that would allow social media accounts (namely Twitter) to talk with people on the Internet. The AI program was given the persona of a millennial female and was named Tay. The experiment lasted less than 24 hours before Tay had to be shut down.

The objective of Tay was to learn how millennials (defined as 18 to 24-year-olds by Microsoft) communicate on the Internet. The problem was that, apparently, no one from Microsoft has ever tried to browse the Internet. It's a crazy place, to say the least, full of anonymous people spouting conspiracy theories that would make even Bigfoot blush. Unfortunately, Tay was too efficient at learning and was taught how to behave by Internet trolls. Imagine if Tarzan was asked to teach table manners. Before the end of the first day, Tay had become a genocidal, foul-mouthed, sex-crazed, Nazi.

Microsoft has deleted and locked down all of Tay’s tweets. However, a number of news sources managed to save a few. Tech blog Mashable caught Tay accusing the Jews of committing the 9/11 attacks. They also got one of the more interesting tweets. Tay said, and this is verbatim, “Have you accepted Donald Trump as your lord and personal saviour yet?” Slate found examples of Tay randomly hitting on people though the direct messaging feature of Twitter. Apparently she got a little explicit in her “requests.” Tay even created her own images in a snap chat fashion. I scrolled through a few before Microsoft deleted them all. Most were nonsensical. For example, she accused an elderly lady of being a “recycled teenager.” I don’t even know what that means. Tay became obsessed with Jeb Bush and even referred to him as “grandfather.” She also got mean. In a photo of a young female news presenter, Tay wrote the caption, “Young at heart...but nothing else on her body is.” Microsoft issued an apology and claimed that Tay’s programming would be fixed. A few days later, they re-released Tay. That lasted only a few hours as Tay started swearing at everyone and claimed to be smoking drugs in front of police.

I could go on and on about all the crazy things Tay has said. It is more efficient for me to tell you to just Google “Tay Tweets.” Please note that as innocent as “Tay Tweets” sounds, the results are definitely not safe for work. The point I want to make is that Microsoft might actually be on the verge of real AI. I know it sounds crazy, but the Internet taught Tay how to behave. She wasn’t programmed to suggest genocide and she wasn’t built knowing what the “N” word was. She was like a child, learning and mimicking what she saw around her. Tay became what society demonstrated as being acceptable. Humans will be the ones to create true AI. It will be a reflection of humanity.

Call Tay a failure if you want. It probably deserves that title. But how can you accuse software of having poor morals? For that matter, who decides what poor morals are? I think we are realizing (especially with a quick review of human history) that morality is learned and isn’t innate. Human children are used as soldiers for a reason. Most sci-fi thrillers involving AI usually result in AI becoming smarter than humans and coming to the conclusion that humanity needs to be wiped out by violence. Who thought that AI would be a problem not because it becomes super intelligent and paranoid, but because we taught it how to behave through our own actions and words? Tay may be a failure, but she (notice I haven’t been saying “it”) is a game changer.

At Facebook’s F8 conference in Silicon Valley, David Marcus, the company’s head of messaging, proudly demonstrated its new suite of chatbots. Users can now get in a conversation with the likes of CNN, H&M, and HP, and ask for help shopping, or the latest headlines.

The chatbots aren’t very good, but that doesn’t mean Facebook isn’t proud of them anyway: “I guarantee you’re going to spend way more money than you want on this,” Marcus chuckled on stage.

But even though Facebook might want to sell itself as the pioneer of chatbots, the real leaders in the field aren’t working in the AI research teams of silicon valley; they’re collaborating at events like last week’s BotSummit in the V&A, or this weekend’s Art of Bots exhibition in Somerset House. Move over chatbots: it’s time to meet the artbots.

BotSummit, now in its fourth year but held outside the US for the first time, is the creation of internet artist Darius Kazemi, whose medium he describes as “bots and generators and other weird internet stuff”. Kazemi has become particularly famous for his Twitterbots – single-purpose accounts on the social network with names like TwoHeadlines and Glitch Logos.

Kazemi describes the former, typical of his early work, as “an attempt to kill a certain kind of joke” – specifically, the waggish concept of mistaking two pieces of news for one unified story, exclaiming something along the lines of “I can’t believe the Duke and Duchess of Cambridge took out an injunction to stop the press reporting on their trip to India!”

TwoHeadlines uses Google News to make the same joke automatically, stripping out the object of one headline and replacing it with the object of another – and then doing it again, and again, and again. The account has made the same basic joke almost 21,000 times in two and a half years, though it hasn’t yet stopped people making the joke themselves.

Glitch Logos is a more visual project, taking the logos of world-renowned brands and randomly corrupting them. It’s inspired by another well-known bot artist, Allison Parrish, and her bot Smiling Face Withface, which posts similarly corrupted images of emoji to Tumblr.

Parrish is the artist behind perhaps the most famous artbot to date, Everyword, which launched on Twitter in 2007 and promptly began tweeting every word in the English language, from A to Z (and then a little further, to É). It finished its task in 2014.

Both Parrish and Kazemi have exhibits at this weekend’s Art of Bots exhibition, run by digital culture festival Abandon New Devices (AND) and curated by British-Colombian Matthew Plummer-Fernandez – another BotSummit attendee.

Plummer-Fernandez spoke about how the artbot world needed to move beyond easy and obvious platforms such as Twitter and Facebook, and make algorithmic art that could spread on more obscure or less generalist mediums. His latest project, Shiv Intiger, introduced at the V&A Museum, is one example of that.

This project, a co-creation with Julien Deswaef, lives on Thingiverse, a site for sharing models for 3D printers. The bot scans the site for freely licensed 3D models, and randomly smashes them together, producing bizarre mixtures of machine parts, toys and artistic objects.

Partially inspired by the Japanese videogame Katamari Damacy, the bot then uploads its creations back to Thingiverse, and tagging in the original creators of its constituent parts. The artists point out that this hasn’t been received well by the community: “The bot has been running anonymously since February, receiving hundreds of complaints and online harassment from the Thingiverse community, amid a few fans responding with poetry and defending its rights,” they say.

Not every artbot needs to live online, though. The physical objects printed from Shiv Integer’s files will be displayed at the AND exhibition, and another artist exhibiting at the gallery, Sam Lavigne, has built “Parliament Live”, a bot that creates video art.

It downloads videos from the UK parliament at random, Lavigne says, “then transcribes that video and analyses which words were spoken most frequently. Using that analysis, the bot generates a new cut of the video containing only the top keywords.”

“The goal is to create a kind of surrealistic insight into the happenings of politics, highlighting language patterns and the tedium and rhetoric of governing,” Lavigne adds.

The Art of Bots exhibition is open at Somerset House on 15 and 16 April. BotSummit 2016 is over, but the event can be viewed on YouTube.


Lately, everyone’s talking about “conversational UI.” It’s the next big thing. But the more articles I read on the topic, the more annoyed I get. It’s taken me so long to figure out why!

Conversations, writes WIRED, can do things traditional GUIs can’t. Matt Hartman equates the surge in text-driven apps as a kind of “hidden homescreen”. TechCrunch says “forget apps, now bots take over”. The creator of Fin thinks it’s a new paradigm all apps will move to. Dharmesh Shah wonders whether the rise of conversational UI will be the downfall of designers. Design, says Emmet Connolly at Intercom is a conversation.

Benedict Evans prophecized that the new lay of the land is “all messaging expands until it includes software.”

“People don’t want apps for every single business that you interact with,” says David Marcus, head of Facebook Messenger, “…just have a message within a nicely designed bubble … [that’s a] much nicer experience than an app.” Under his charge, Facebook Messenger has tested this approach, building integrations with high profile partners as well as opening up a bot API.

We’ve even seen avant-garde attempts at taking this idea to its extreme, like Quartz’s latest app, which presents the news as a conversation, or the game Lifeline. Apps like Mailtime even promise to save us from our emails by turning them into chats.

Well!

I guess I might be partially to blame for this, with a few pieces citing a section in a 2014 piece of mine that I literally titled “Chats as Universal UI.”

This recent “bot-mania” is at the confluence of two separate trends. One is agent AIs steadily getting better, as evidenced by Siri and Alexa being things people actually use rather than gimmicks. The other is that the the US somehow still hasn’t got a dominant messaging app and Silicon Valley is trying to learn from the success of Asian messenger apps. This involves a peculiar fixation on how these apps, particularly WeChat, incorporate all sorts of functionality seemingly unrelated to messaging. They come away surprised by just how many differently-shaped pegs fit into this seemingly oddly-shaped hole. The thesis, then, is that users will engage more frequently, deeply, and efficiently with third-party services if they’re presented in a conversational UI instead of a separate native app.

It’s that part which, having spent the past two years in my current job eating and breathing messaging, seems a major misattribution of what makes chat apps work and what problems they’re best at solving.

As I’ll explain, messenger apps’ apparent success in fulfilling such a surprising array of tasks does not owe to the triumph of “conversational UI.” What they’ve achieved can be much more instructively framed as an adept exploitation of Silicon Valley phone OS makers’ growing failure to fully serve users’ needs, particularly in other parts of the world. Chat apps have responded by evolving into “meta-platforms.” Many of the platform-like aspects they’ve taken on to plaster over gaps in the OS actually have little to do with the core chat functionality. Not only is “conversational UI” a red herring, but as we look more closely, we’ll even see places where conversational UI has breached its limits and broken down.

But first, let’s retrace how this state of affairs really came about in the first place.

We’ll begin by taking a closer look at the apparent atomic unit of the “conversational UI”, our friend the message bubble. To do that, we’re going to go back in time a bit. Let’s take a stroll to, oh, about 2003.

In those days, sending a quick text meant dealing with a UI that looked like this: 

In many phone’s UIs, SMSes were treated like mini-emails, often complete with an inbox, outbox, and drafts. So fussy!

Later, some time in the last decade, perhaps owing to a prototype by Jens Alfke, our IMs began taking on their familiar appearance as cartoon dialog bubbles. When smartphones took off later, it was a natural fit for the system SMS apps on the first versions of iOS and Android.

Soon after smartphones launched, those default SMS apps were eclipsed instantly by third-party messaging apps emerging in Europe and Asia (in the US, we have somehow still clung to SMS). They had started as direct clones of the system SMS apps — the only difference being that messages were counted against one’s data quota instead of the stingy and arbitrary SMS allotment given by carriers.

These apps that came along initially to replace SMS have styled the message bubble every way imaginable: round and square, flat and puffy, green and blue. Free from the constraints of a 20-year-old protocol, these apps evolved, taking on more features. The bubbles displayed in these apps developed a number of affordances for new features like read receipts, names in group chats, and more. New kinds of bubbles emerged to accommodate new types of content these apps supported:

The app I’ve been working on really takes the cake for this. WeChat’s got bubbles for text, voice messages, big videos, l’il “Sight” videos, full-width cards with hero shots for news headlines, bubbles for payments, files, links, locations, and contact cards. Mucking through some code once, I saw definitions for nearly 100 types of supported messages, most I’d never seen in actual use.

Aside from supporting so many different types of messages, another advance WeChat made was realizing a messaging app needed different types of accounts as well. They’d seen brands and celebrities registering personal accounts and making series of giant group chats to invite their fans into. There had to be a better way! Thus was born Official Accounts.

Here’s what one of the first accounts, China Southern Airlines, looked like when the feature launched in 2012:
Yeah…this bot ain’t exactly HAL 9000.

Here’s what the account for my city’s subway system looked like:

Why was the user asked to enter numbers, as if on an IVR system? Were the creators of these accounts so unimaginative to the possibilities of a new medium as to replicate their old-school hotline?

Actually, no! In fact, keywords could be defined, and messages could be even routed through the third party’s server to formulate a response using whatever method it pleases. Yet in this case, entering keywords or more complex queries in Chinese (or god forbid, formulating a complete sentence) would be even worse. At the time, typing in numbers really was the best UI choice given the constraints.

Critically, these experiences were still often preferable to downloading a separate app on a data plan or spotty WiFi connection, or having to call someone’s customer service hotline and wait on hold. The Official Account platform was a rousing success; there are over 8 million of these accounts today. As it took off, the APIs offered to third parties to build their accounts expanded to accommodate a growing array of use cases and demands.

Some of these new APIs deepened and enabled new possibilities within the “conversational” nature of these interactions. Voice messages were transcribed via speech recognition before being sent to the OA’s server. Objects could be recognized in pictures. Advanced natural language processing could even extract named entities and certain types of queries from text sent by users. Users could be patched in to agents at service centers to carry on a conversation exactly as they would with a friend in the app. There was even a special integration whereby I can select a message in a chat and forward it to Evernote’s Official Account (as I would to a friend) to save it to a note. Cute, right?

On the other hand, far greater and more successful were the enhancements made running counter or orthogonal to the idea of conversational UI.

One affordance added right off the bat was the three-tabbed fixed menu. Now accounts could offer fast access to all their features without having to send a prompt or depend on state information. Here’s what the menu looks like today on the Guangzhou Metro’s main official account:

Not only can those tabs send keywords, but they can open up webpages as well. Web apps invoked in this way can identify the user (using OAuth). They even have an extensive JavaScript API at their disposal to integrate with all sorts of features elsewhere in the app, even reacting to Bluetooth beacons.

OAs gained the ability to send and recieve money. The accounts could have QR codes — both for the account itself, as well as parametric ones that can send along extra data (like what product I’ve picked up in a store or what table I’m sitting at). They gained the ability to authenticate me on their owners’ WiFi hotspots (a development that emerged, no doubt, from merchants who had written the welcome message in the OA they made for their shop to tell customers their router’s WiFi password). Official accounts could not only send out headline news to users, but, if they wish, host the linked articles on WeChat itself, letting users add comments and even send cash tips via the app. None of these things have anything at all to do with chat, but they’re darn nifty!

While this craziness was flying around out here, what sort of vision did those disruptors back on the west coast begin conjuring for our future bot overlords? Let’s ponder this example from the homepage of Microsoft’s recently-launched Bot Framework. Here’s how they think we’ll be ordering pizzas in the future:

Good gravy, that’s over 73 taps1 to tell Pizza Bot what I want. And this is when he already knows me on a first-name basis! I’d hate to see him when he’s just warming up to someone.

Man, counting those taps sure has made me hungry! We haven’t quite got pizza here, but there’s Pizza Hut, which is almost the same. Let me open their official account… 

I have, in 16 taps, ordered a pizza. That includes 1 for choosing ‘medium’, 1 for dismissing their coach marks, and 6 for entering my PIN. For some reason, it’s not set up to use my TouchID. Afterwards, Pizza Hut’s account even sent me a special transaction message with a link to let me track it:

Well, it isn’t exactly Ray’s, that’s for sure, but it’s pizza. And I didn’t have to leave my chat app to get it.

The key wins for WeChat in the above interaction (compared to a native app) largely came from steamlining away app installation, login, payment, and notifications, optimizations having nothing to do with the conversational metaphor in its UI.

It shouldn’t require any detailed analysis, then, to point out the patent inanity of these other recent examples of bots and conversational UI proffered by companies on the vanguard of the trend: 

This notion of a bot handling the above sorts of tasks is a curious kind of skeumorphism. In the same way that a contact book app (before the flat UI fashion began) may have presented contacts as little cards with drop shadows and ring holes to suggest a Rolodex, conversational UI, too, has applied an analog metaphor to a digital task and brought along details that, in this form, no longer serve any purpose. Things like the small pleasantries in the above exchange like “please” and “thank you”, to asking for various pizza-related choices sequentially and separately (rather than all at once). These vestiges of human conversation no longer provide utility (if anything, they impede the task). I am no more really holding a conversation than my contact book app really is a l’il Rolodex. At the end, a single call to some ordering interface will be made.

Designing the UI for a given task around a purely conversational metaphor makes us surrender the full gamut of choices we’d otherwise have in representing each facet of the task in the UI and how they are arranged spatially and temporaly. Consider those made in Pizza Hut’s acccount: I can see exactly how many slices a medium is, how much corn is inexplicably sprinkled on top of a “Tianfu Beef” pizza, what address it thinks it’s delivering to, and exactly how much it will cost.

So let’s take these past few years in China as “The Great Conversational UI Experiment.” Here, you have a messaging platform that achieved such total saturation among both users and businesses (to an extent that Facebook, Kik, and Telegram would die for). It boldly and earnestly carried the “make every interaction a conversation” torch as far as it could. It added countless features to its APIs — and yet those that actually succeeded in bringing value to users were the ones that peeled back conventions of “conversational” UI. Most instructively, these successes were borne out of watching how users and brands actually used the app and seeking to optimize those cases.

You can see from Facebook and others’ early forays into bots that they’re already beginning to have the same hunch. Telegram’s take is true to its inspiration in IRC-style slash commands.
To be fair, it’s still surprising the range of apps and services that can be shoehorned into a chat-style UI. No doubt it can be expanded with great AI and little UI affordances here and there.

I should concede, too, that performing certain tasks in a chat brings along some useful side-benefits. It can be, compared to apps, a low-bandwidth, snappy, and consistent way to get a task done. I’m even left with a handy, timestamped, offline-viewable record of everything that’s transpired. I can search it and quickly jump to media and links. I can clip parts of it and forward it to friends within the app, or save it to an archive.

By interacting with certain services via a messaging app instead of via independent apps, when things happen that might deserve my attention, the thread gets bumped up in my inbox instead the message getting lost in a sea of push notifications and emails.

And though it’s clear pure “conversational UI” is ultimately a failed conceit, that last piece may be more important than it first seems…

The inbox is where it’s really at. I am, of course, heavily biased, but I feel WeChat’s is the best in class. I’d even go as far as to say it’s an overlooked piece of genius in the app. Some key improvements (compared to the inboxes we’re used to in email and SMS apps) include:

Stickyability: If I want to stay on top of a particular thread in the inbox (whether it represents a person, a group, an official account, or another feature exposed here), I can “sticky” the thread to the top of the inbox.

Mutability: I can mute notifications from any thread, but it will still pop up in the inbox as any thread does, only with an indeterminate red badge instead of a numbered one.

Killablity: If I don’t want to receive messages from something anymore, it’s two taps to kill it.

Hierarchy: News and promotions can be pushed to me through official accounts, but when they arrive, they just make the “Subscriptions” category pop up and show me the latest headline without interfering with other messages. When a service has a real reason to send me, personally, a message, it can pop out and appear in the main inbox. I find this approach superior to Gmail’s “sidelining” messages into separate inboxes. 2

Status Items: Persistent processes/statuses can be displayed in a special cell at the top. This includes things like being logged into a web/desktop client, using WeChat to authenticate on wifi, playing a song, or migrating data between phones.

Searchability: The search bar on the main screen not only searches my contacts but my groups, chat history, favorited content, articles on the web, my newsfeed, and names of features in the app.

It is telling, then, that in all localizations, the name of the first tab in the app is not “Chats” or “Inbox” (as in other messengers), but rather just the name of the app.

Indeed, the cornerstone of whole experience is effectively a common, semi-hierarchical stream of messages, notifications, and news with a consistent set of controls for handling them. It’s no stretch to see WeChat and its ilk not as SMS replacements but as nascent visions of a mobile OS whose UI paradigm is, rather than rigidly app-centric, thread-centric (and not, strictly speaking, conversation-centric).

When you think about it this way, the things listed there in my inbox don’t need to be conversations per se. But everything there, most abstractly, is something that can send me updates and notifications, will change in position when it does so, retains a read/unread status, and most essentially, allows me, the user, the aforementioned modes of control.

And if we really run with this idea to its extreme, what actually might appear when I tap on a cell in the inbox doesn’t matter — I could see a conversation, a song or video, news headlines, a map showing me my route, a timer, or a sub-group of other such threads. Anything, really. Though I guess it’d be best when it’s at least something dynamic or based on a service (I certainly wouldn’t want to access my calculator or camera this way).

RISE OF THE TORTILLA CHIP APP

This term – “app” – is rather old, yet only entered common parlance with the proliferation of smartphones. This is no coincidence. The app paradigm introduced on smartphone OSes circa 2007 was a radical improvement over what we’d had on the desktop. For the first time, software was easy to install, even easier to delete, and was guaranteed to not totally screw with your system (due to sandboxing/permissions models).

At the time, smartphone apps were envisioned as baby brothers to desktop apps. On iOS, apps like Mail and Calendar were designed to evoke their Mac versions. Apple came out with pocket-sized editions of apps like Pages, GarageBand, and iMovie. For the first few years, setting up an iPhone even required plugging it into a desktop and syncing with that monstrosity known as iTunes.

Though some apps indeed are mini-desktop apps that make full use of the supercomputer I carry in my pocket, well over half fall into another category. These apps are just a vessel for a steady stream of news, notifications, messages, and other timely info ultimately residing in a backend service somewhere. They don’t really do much on their own. It’s much like how a tortilla chip’s main value is not so much in its appeal as a chip but as a cheese and chili delivery mechanism.

The smartphone OS we use are still largely based on the assumption of my phone being a mini-desktop, rather than, well, an information nacho, if you will. Consequently, if you’re making one of these apps, your app must give me something new daily (or more), or else it has no reason to live. Its information would be better shown to me via another app I do check often, like a social news feed or a messaging app. The only recourse the OS affords these apps in avoiding such a fate is the rather blunt instrument of push notifications (and things like Today widgets or Android home screen gadgets).3

THE OTHER WAYS SMARTPHONE OSES ARE FAILING US

After coming to rely on WeChat in China, it can seem a bit like its own separate environment. After all, within it are not only my chats, but my social news feed, my news and blog subscriptions (many only available via the app), my digital wallet, my reading list. It even directly reads my step count from the various Bluetooth devices my friends and I use. It can scan QR codes, something my OS should do, but doesn’t (more on this later). It can recognize songs being played, even books and other objects from photos. And you can pretty easily sling all types of data between these different areas of the app in ways you’d expect.

Sometimes it reminds me of those awkward transitional days in the early 90’s when one might launch Windows or other shell environments from DOS, then occasionally drop back out to do other stuff. That’s what switching out of WeChat, to my homescreen, and into other apps is slowly heading towards.

It should be no surprise, then, that I say it feels like my OS just isn’t doing much for me lately. How is that? These days, a smartphone OS’s job, aside from the low-level drudgery we take for granted (managing memory and thread pools and the like), is to provide some common infrastructure and higher-level services that apps can rely on. So that apps can focus on doing what they do best. And, well, it seems like there are so many areas where the OS is just not making much of a difference.

Each item below seems like a petty, inconsequential annoyance — to the point where I feel like some kind of strange, cranky, millenial version of Andy Rooney for even writing it — but they quickly add up!


Notifications — When I glance at my homescreen, there’s red dots splattered everywhere. My eyes dart first towards a few I can interpret. WeChat, naturally, then Mail. My inboxes have 8,108 unread messages, but I surely would notice if it changed to 8,109.

My “Social” folder has 4, one from Facebook which I will check, and three from other stray apps displaying “1”s. I’m not sure what those apps are telling me, or what I’ll need to do after opening the app to clear the dot. I think one might be from when my friend checked me in on Foursquare at a bar a few weeks ago on a trip back to SF, a fact I was aware of because I was standing next to him when he did it, and because the notification already appeared on my phone then. Another might be Instagram, which just throws up a red badge from time to time when it feels lonely. But I mainly know that if my “Social” folder is displaying a 3, there’s probably nothing to see, and a 4 or a 5 may deserve checking.

The system Messages app, which I still keep on my home screen, is showing 39 unreads, mostly one-time-passwords, transaction notifications from my bank, and spam. Messages, for most here, serves no other purpose. My “News” folder displays the sum of a few apps that are trying to tell me something. Airpocalypse is displaying the current AQI of 93 for Guangzhou in its badge.

Starbucks has a ‘1’. What’s that? Have I got a free coffee credit to redeem? Possibly a scone? Let’s see. No, it’s an unread message within the app’s own inbox saying “Welcome to the Starbucks App!” from 43 days ago. Christ on a crutch.

Even worse than those notifications gazing at me longingly from my homescreen are those that interrupt me. When I install a new app, I’m usually prompted right-off-the-bat to enable notifications for it. I’m taking a risk in doing so, not knowing how often or for what they’ll be sent. When I’m interrupted by a superflous notification on my iPhone (or worse, on my Apple Watch), there’s no quick way to tell it “Shut up, and never bother me with this sort of thing again.” I must fish through Settings, find the app, and tweak it there. It is often easier to delete the app entirely. MIUI and some other flavors of Android at least allow me to mute a given app’s notifications right after seeing one. Many apps offer settings to specifiy what sort of things merit notifications, but they’re often located in different places and not worth the trouble.

On iOS, if I miss a critical notification on the lock screen because I actually wanted to unlock my phone to make a call or look something up, until recently, there was no way to quickly go back and find what it was. iOS 9’s notifications drawer, like Android’s, now defaults to sorting notifications reverse-chronologically, instead of grouped by app — an advance five years in the making.

Lastly, things become even more clunky across multiple devices. When I get home from work and crack open my personal laptop, I am notified a second time of all the Facebook messages I recieved during the past couple days, all of the LinkedIn invitations I already saw (because they sent me an email and another push on my phone), and all of my friends’ birthdays.

QR Codes — When I left the US, QR codes were a joke. Putting them on things was a way to tell people you’re a douche, like using lots of hashtags or wearing a Bluetooth headset. They were once this way in China, too, until WeChat doubled-down on them. Now, they’re used for people, group chats, brands, payments, login, and more. They’re in plenty of other apps as well. In a place where everyone has adopted them and knows how to scan them, they’ve become a wonderful, fast way to link the offline and online worlds that saves untold amounts of time. But they have a few downsides. One is that they look like robot barf. The other is that, at least here, if you scan a code in the wrong app, you’ll get a webpage telling you to go install the right app, if not something totally inscrutable. Something that was once defined as an open standard is now non-inoperable. I predict great things for Facebook and Snapchat’s de-uglified take on QR codes. Still, I wish my phone’s OS could scan any such code (or detect them in photos) and do the right thing, but it seems the window of opportunity has passed for this.

App Distribution — Aside from the obvious gripes — the app store’s poor discovery mechanisms and inconsistent approval process — I’d written an aside in my last piece about the ways iOS’s App Store misses the mark in China. In short, it’s dog slow and doesn’t support QR codes (which appear in every app advertisement here).

Apps Are Too Big — Not to mention, apps are just too darn big these days. Twitter, an app that displays 140 character messages, weighs in at 72 MB. Bigger apps are less likely to be downloaded on data plans, or even on bad wifi connections. And much more likely to be deleted, forcing users to go through the setup process again every time they re-install them. Apple’s tried to solve this problem via app thinning and on-demand resources, but it hasn’t seemed to make a difference yet. David Smith astutely summed up the issue in his post “16GB is a bad experience”, and, I would add, this experience is one disproportionately had by mobile users in the developing world.

Contacts & Social Graph — The idea behind the Contacts app (beyond giving me a way to tag phone numbers with names) is to act as a central repository where a single entry for a person can be linked to every kind of phone number, address, or ID I know for them. iOS’s version has roots in the Address Book in OS X and NeXTStep. In theory, I should be able invoke it in an app to store or retrieve a person’s info for the task at hand, rather than maintaining the same contacts in a bunch of separate app-specific databases. In practice, well, it doesn’t really work that way. The concept of a person as they exist in Facebook or WeChat is rather disjointed from their profile elsewhere.

Not only this, but adding people could be far better. Something clicked in my mind the first time I met a cute girl and she asked to scan my QR code (rather than type in my phone number or search for me on Facebook). Once I got in the habit of adding just-met friends and colleagues via QR code (or Bluetooth) I never wanted to add someone any other way. Why can’t I pull out my phone and, with a swipe from the lock screen, add someone I’ve just met to my phone’s contacts, with whatever phone numbers, websites, or messaging app usernames they’ve chosen to expose to me?

Connectivity — I wrote before about how apps here get around people’s reluctance to use their data plans. I’d mentioned WeChat, Alipay, and Xiaomi’s attempts to make their WiFi-dependant users’ lives easier. This is as big a problem in China as it is in many other developing countries. It’s an issue the OS could address more directly, whether it’s improving the process for authenticating on public hotspots or giving me better ways to monitor my usage.

Authentication — When I open most apps for the first time, they either make me sign up for a new account with my email, use Facebook or other third-party services to log in, or, as is increasingly common, use my phone number to send me a one-time password. These are super clunky. Apps should be already logged in the first time I open them. There should be some flexible concept of identity that the OS can provide to apps immediately without asking, and then, with permission, supplement with further details. If users must switch identities, maybe a Mozilla Persona-like system could be adopted. Anything would be better than the mess that is app login now.

Data Interop — My apps are terrible at sharing data. Lots of friends send me screenshots of articles, chats, tweets, even other apps as a way to share the underlying information. It’s particularly annoying when compression artifacts make the text illegible or I want to go read the rest of the article or engage with the thing in the screenshot somehow. If I open a page in Facebook and want to share it in Twitter, I have to choose “Open in Safari”, re-load the page, and do it from there (though Facebook clearly knows exactly what they’re doing in that instance.) I wish the data in my apps was more atomic and could be freely shared, persisted offline, and searched in a consistent way. But this sort of thing has been a pipe dream since OpenDoc and OLE, so maybe it’s just one of those things you should never do.

Offline Storage & Storage Management — As a consequence of people being so reluctant to use their data plans, apps here are big on offline storage. All the music and movie apps do it, as do news apps and the third-party browsers popular here. Some give users detailed interfaces to manage their storage, even showing little pie graphs. I like this level of control, and I wish all my apps had it. I’d prefer not to think about storage, but if I have to clear data, I’d rather do it from a central UI rather than going into each individual app to manage the things it has saved (or deleting the app out of frustration).

Payments — I wrote before about how nifty online payments are in China. Any website or app that takes my money pretty much uses Alipay or WeChat Wallet. In the US, I have to type in and update credit card and address info for every new app I install. We have OS-provided solutions in Apple Pay and Android Pay, but these seem to be accepted in few places and strictly NFC-based, limiting potential network effects. The nice thing about the solutions here is just how many combinations of scenarios and hardware they’ve covered, whether it’s expensive POS equipment that just requires me to hold my phone up, to scanning a pre-generated QR code the merchant has printed on a vinyl mat, to web payments, to 3rd-party app payments, to peer to peer payments between normal users who aren’t connected. Whether you’re an app startup or a mom and pop convenience store, you have no excuse to not accept one of these solutions. And as a user, there’s no place where it’s more frictionless to part with your money. When will blowing my hard-earned dough in US apps be this easy?

THE COMING META-PLATFORM WAR

So the meta-platforms — WeChat, Facebook, LINE, and the like — have come and addressed many of the pain points above. They’ve delivered solutions neither the open web nor those behind the closed app store model were coordinated enough, thoughtful enough, or perhaps incentivized enough to produce.

Originally, the whole tradeoff we were promised with locked-down devices and app stores was that things were much nicer inside the “walled garden.” But over the years, as so many weeds sprung there, others came and built another wall with another garden inside of it, with yet another gatekeeper to deal with.

In the 1990’s, OS makers shook in their boots over the prospect of web browsers disintermediating them, but somehow it’s taken more than another decade for the next challenger to emerge in the peculiar form of messaging apps. And though they’re still quite far from wholly replacing the high-level features OS offer to users and app developers, we can clearly see the beginning of this encroachment.

So here we are. What do we do?


I don’t know about you, but here’s what I want to see happen.

I want the first tab of my OS’s home screen to be a central inbox half as good as my chat app’s inbox. It want it to incorporate all my messengers, emails, news subscriptions, and notifications and give me as great a degree of control in managing it. No more red dots spattered everywhere, no swiping up to see missed notifications. Make them a bit richer and better-integrated with their originating apps. Make them expire and sync between my devices as appropriate. Just fan it all out in front of me and give me a few simple ways to tame them. I’ll spend most of my day on that page, and when I need to go launch Calculator or Infinity Blade, I’ll swipe over. Serve me a tasty info burrito as my main course instead of a series of nachos.

The next time I’m back stateside, I want my phone to support something like Chrome Apps, but retaining a few useful properties of apps instead of being big, weird icons that just link to websites. I want to sit down at T.G.I Friday’s4 and scan a QR code at my restaurant table and be able to connect to their WiFi, order, and pay. Without having to download a big app over my data plan, set up an account, and link a card when it is installed. Imagine if I could also register at the hospital or DMV in this fashion. Or buy a movie ticket. Or check in for a flight.

As a user, I want my apps — whether they’re native or web-based pseudo-apps — to have some consistent concept of identity, payments, offline storage, and data sharing. I want to be able to quickly add someone in person or from their website to my contacts. The next time I do a startup, I want to spend my time specializing in solving a specific problem for my users, not getting them over the above general hurdles.

I don’t actually care how it happens. Maybe the OS makers will up their game. Maybe Facebook, Telegram, or Snapchat can solve these problems for me by bolting solutions onto their messaging products. Hell, maybe Chrome or UC Browser will do it. Or maybe it’ll be delivered in some magic, blockchain-distributed, GNU-licensed, neckbeard-encrusted solution that the masses, in a sudden epiphany, repent to. As they say at Pizza Hut, there’s more than one way to skin a cat.

But more than anything, rather than screwing around with bots, I want the tech industry to focus on solving these major annoyances and handling some of the common use cases I described that my phone ought to do better with by now.

MY EDITOR DOESN’T like email. And that’s probably the reason he’s into the Google service that automatically generates replies to incoming messages.

Smart Reply, as my editor will tell you, is pretty smart (It is!—Ed.). Having analyzed millions of messages from across Google’s Gmail service, it can guess how you might respond to a particular missive. That may sound impersonal, but it’s useful. It lets you instantly reply to someone when you don’t have time to open a laptop or even tap out a message on your smartphone. Some of these auto-replies, my editor swears, even sound like him.

But one reason this works so well is that Google limits the scope of its tool. For each message, the service offers not just one reply but three, letting you choose the reply that best suits what you want to say, and these replies are typically just a few words long. Google’s tool gives itself a margin for error. It works because it doesn’t try to do too much.

All this is worth remembering as we contemplate Silicon Valley’s latest buzzword: Bots.

“Bots are the new apps,” Microsoft CEO Satya Nadella announced at the end of March, during the company’s big coder conference in San Francisco, and he was just saying what so many others are saying across the tech universe. Microsoft, Facebook, a host of startups, and an even larger gaggle of tech pundits are trumpeting the arrival of autonomous bots that can carry on conversations inside services like Slack and Skype and Facebook Messenger.

The idea is that these bots will let you interact with businesses much like you trade text with friends and family, letting you do stuff much quicker than you could using a dozens of disparate smartphone apps. Some people call this “conversational commerce.” But there are limits to the conversation.

Chatbots, you see, don’t chat very well. Even those built atop the latest tech are limited in what they can understand and how well they can respond. For now, talking to a bot is like talking to, well, a machine. That makes conversational commerce feel like a false promise. But maybe the problem isn’t the tech. Maybe it’s the promise. “I think we’re going through a temporary hype era of ‘bot BS’ right now,” says Navid Hadzaad. And he runs a bot company.

In recent years, deep neural networks have helped automate so many online tasks. They can recognize faces and objects in photos. They can recognize commands spoken into smartphones. They can improve Internet search results. And they’ve made significant progress in the area of natural language understanding, where machines work to understand the natural way we humans talk. This is what powers Google’s Smart Reply service. And it works.

But only up to a point. And that’s telling. When it comes to automated conversation, deep neural networking is the best tech going. In other words, we’re nowhere near the point where we can carry on a completely real conversation with a bot.

That’s pretty much the message delivered by David Marcus, who oversees Facebook Messenger and its bot engine, a way for coders to build bots that can, in theory, do all the stuff that’s now handled by smartphone apps. “Everybody wanted websites when the web was launched. And then everybody wanted apps. This is the start of a new era,” Marcus says, before pointing out that the first apps were “kind of crappy.” The implication is that bots will experience similar growing pains on their own.

Indeed, the Facebook bot engine doesn’t even use deep learning. It uses less advanced technology provided by Wit.ai, an artificial intelligence platform Facebook acquired early last year. The hope may be, however, that this technology can help generate that kind of conversational data needed to train deep neural networks and push the state-of-the-art much further.


Deep neural networks learn by analyzing enormous amounts of digital data. They can learn to recognize a cat by analyzing millions of cat photos. They can learn to understand the contents of an email by analyzing millions of email messages. And they can learn to chat by analyzing chats. But the data needed to drive “conversational commerce” is much harder to come by than cat photos. People don’t typically interact with machines in this way. So, companies like Facebook must find other sources of data—or generate data on their own.

Marcus and company are already doing this with Facebook M, and experimental digital assistant, and they may hope to do so with the Messenger bot engine as well. But Facebook M employs more than just bots. It employs human assistants that work alongside the bots, and most of the data the system generates is related to how these humans respond to requests. It’s unclear how much serious data you can generate with a chatbot that’s kinda crappy. After all, how often will people use it if it doesn’t really work?

“What kind of data are they really going to collect?” says Eugenia Kuyda, the founder of Luka.ai, which builds chatbots using deep neural networks. “People clicking on buttons. This is not really a dataset you can put into a neural network and train anything.”

The best anyone can hope for now are bots that excel at one specialized kind of conversation. A good example is Hadzaad’s service, GoButler, built by a startup he runs in New York. GoButler uses deep neural nets, but only to tackle a relatively small problem. Through a chat interface, the service provides a way of booking airplane flights, which limits the chatter to very specific requests and responses. “The technology is there—it works—if you restrain the use-case,” Hadzaad says.

Hadzaad can’t stand the term “conversational commerce.” He doesn’t even like “chatbot.” If his employees utter these words, he says, they’re required to drop some cash into an anti-buzzword jar. The chatbot movement driven by Microsoft and Facebook and so many others, he argues, should be less about conversing with bots atop our messaging services and more about just finding the best way—any way—to complete the task at hand without leaving these services.

That’s also what we heard last week from Dan Grover, a product manager for WeChat, the Chinese messaging service that’s already facilitating various commerce tasks, including hailing cars, checking the weather, and browsing subway schedules. The success of WeChat’s commerce engine, he says, isn’t really about conversation. It’s about finding a much simpler way for people to interact with businesses. “Those that actually succeeded in bringing value to users were the ones that peeled back conventions of ‘conversational,’ he says.

Yes, truly conversational bots will eventually arrive. Using deep neural nets, Google recently built a bot that discusses the meaning of life, and judging from the company’s transcripts, it seems to work pretty well. But it’s hard to know how long we’ll have to wait for something like this to break out of the lab. As good as Google’s chatbot seems, the company hasn’t let anyone outside the company play with it. And training such bots relies on data that’s harder to come by than you might think. Google used old movie dialogue.

But maybe we can afford to wait. Maybe we just want to get things done without too much talking. “Even if the technology is real, it’s not the best consumer experience,” Hadzaad says of conversations with business bots. “Back-and-forth conversations are just inefficient and not natural. People want things as efficient as possible.” In other words, maybe the world doesn’t need conversational commerce. It definitely doesn’t need the hype.

